{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook is for removing outliers from our dataset. Currently we remove businesses that have a low number of orders (below the 1% quantile.) We then generate some distribution plots and compare it to our plots from distribution_analysis.ipynb. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as F\n",
    "from pyspark.sql.functions import col, to_date, when, concat, lit\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"green preprocessing\") \\\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \\\n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\") \\\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\") \\\n",
    "    .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = \"../../../data/insights/joined.parquet\"\n",
    "df = spark.read.parquet(path1)\n",
    "df.show(5)\n",
    "df.printSchema()\n",
    "print(\"length:\",df.count())\n",
    "df_pandas = df.toPandas()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "# Initialize an empty list to hold the outliers\n",
    "\n",
    "for segment in df_pandas['segment'].unique():\n",
    "    # Filter the dataframe for each segment\n",
    "    segment_df = df_pandas[df_pandas['segment'] == segment]\n",
    "    print(segment)\n",
    "    plt.figure(figsize=(6,4))\n",
    "    sns.scatterplot(x='average_consumer_fraud_probability', y='number_of_orders', data=segment_df)\n",
    "    plt.title(f'Segment: {segment}')\n",
    "    plt.xlabel('Average Consumer Fraud Probability')\n",
    "    plt.ylabel('Number of Orders')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "# Initialize an empty list to hold the outliers\n",
    "\n",
    "# Define a function to calculate upper bound outliers\n",
    "def get_outliers(df, column_name):\n",
    "    lower_bound = df[column_name].quantile(0.01)\n",
    "    print(lower_bound)\n",
    "    return df[df[column_name] <= lower_bound], lower_bound\n",
    "\n",
    "outliers_list,lower_bound = get_outliers(df_pandas,'number_of_orders')\n",
    "    \n",
    "# Create a DataFrame from the outliers_list\n",
    "outliers_df = pd.DataFrame(outliers_list)\n",
    "display(outliers_df)\n",
    "print(\"length: \",len(outliers_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_outliers = outliers_df.groupby('segment').size().reset_index(name='count')\n",
    "display(grouped_outliers)\n",
    "display(\"outlier_merchant_fraud\",outliers_df.groupby('segment')['average_merchant_fraud_probability'].describe().reset_index())\n",
    "display(\"outlier_consumer_fraud\",outliers_df.groupby('segment')['average_consumer_fraud_probability'].describe().reset_index())\n",
    "display(\"cost of order\",outliers_df.groupby('segment')['average_cost_of_order'].describe().reset_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_plot = ['average_merchant_fraud_probability', 'average_consumer_fraud_probability','average_cost_of_order']\n",
    "\n",
    "for col in columns_to_plot + ['number_of_orders']:\n",
    "    plt.figure(figsize=(8,5))\n",
    "    sns.histplot(outliers_df[col], kde=True, bins=30)  # you can adjust the number of bins as needed\n",
    "    plt.title(f'Outliers Distribution of {col}')\n",
    "    plt.xlabel(col)\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas_cleaned = df_pandas.loc[df_pandas['number_of_orders'] > lower_bound]\n",
    "print(\"outliers removed length:\", len(df_pandas_cleaned))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each segment and plot\n",
    "for segment in df_pandas_cleaned['segment'].unique():\n",
    "    segment_df = df_pandas_cleaned[df_pandas_cleaned['segment'] == segment]\n",
    "\n",
    "    # Filter the cleaned dataframe for each segment    \n",
    "    # Plotting the scatter plot for merchant fraud\n",
    "    plt.figure(figsize=(5,3))\n",
    "    sns.scatterplot(x='average_consumer_fraud_probability', y='number_of_orders', data=segment_df)\n",
    "    plt.title(f'Consumer Fraud: Segment {segment} (After Removing Outliers)')\n",
    "    plt.xlabel('Average Consumer Fraud Probability')\n",
    "    plt.ylabel('Number of Orders')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of columns to analyze\n",
    "columns_to_analyze = [\n",
    "    \"average_consumer_fraud_probability\", \n",
    "    \"avg_median_age\", \n",
    "    \"avg_total_weekly_personal_income\", \n",
    "    \"take_rate\", \n",
    "    \"average_cost_of_order\", \n",
    "    \"number_of_orders\", \n",
    "    \"number_of_unique_consumers\",\n",
    "    \"average_merchant_fraud_probability\",\n",
    "    \"average_consumer_fraud_probability\", \n",
    "]\n",
    "\n",
    "df_pandas = df_pandas_cleaned\n",
    "# For each column, calculate summary statistics and plot the distribution\n",
    "for column in columns_to_analyze:\n",
    "    summary_stats = df_pandas[column].describe()\n",
    "    print(f\"Summary Statistics for {column}:\\n\")\n",
    "    print(summary_stats)\n",
    "    print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "    # Plot Distribution\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.hist(df_pandas[column], bins=100, color='#86bf91', rwidth=0.8)\n",
    "    plt.title(f'Distribution of {column}')\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel('Number of Merchants')\n",
    "    plt.grid(axis='y', alpha=0.75)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(df_pandas_cleaned)\n",
    "agg_data = df.groupBy(\"segment\").agg(\n",
    "    F.mean(\"average_consumer_fraud_probability\").alias(\"mean_consumer_fraud\"),\n",
    "    F.stddev(\"average_consumer_fraud_probability\").alias(\"stddev_consumer_fraud\"),\n",
    "    F.mean(\"number_of_orders\").alias(\"mean_orders\"),\n",
    "    F.stddev(\"number_of_orders\").alias(\"stddev_orders\")\n",
    ")\n",
    "\n",
    "# Convert the aggregated data to Pandas DataFrame for visualization\n",
    "agg_data_pandas = agg_data.toPandas()\n",
    "\n",
    "# Plotting\n",
    "fig, axes = plt.subplots(2, 1, figsize=(12, 10))\n",
    "\n",
    "# Average consumer fraud probability by segment\n",
    "sns.barplot(x=\"segment\", y=\"mean_consumer_fraud\", data=agg_data_pandas, ax=axes[0])\n",
    "axes[0].set_title('Average Consumer Fraud Probability by Segment')\n",
    "axes[0].set_ylabel('Mean Consumer Fraud Probability')\n",
    "\n",
    "# Number of orders by segment\n",
    "sns.barplot(x=\"segment\", y=\"mean_orders\", data=agg_data_pandas, ax=axes[1])\n",
    "axes[1].set_title('Average Number of Orders by Segment')\n",
    "axes[1].set_ylabel('Mean Number of Orders')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by segment and aggregate total sales for each segment\n",
    "agg_sales = df.groupBy(\"segment\").agg(\n",
    "    F.sum(df.number_of_orders * df.average_cost_of_order).alias(\"total_sales\")\n",
    ")\n",
    "\n",
    "# Convert the aggregated data to a Pandas DataFrame for visualization\n",
    "sales_pandas = agg_sales.toPandas()\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.pie(sales_pandas[\"total_sales\"], labels=sales_pandas[\"segment\"], autopct='%1.1f%%', startangle=140, colors=sns.color_palette(\"Set3\", len(sales_pandas)))\n",
    "plt.title('Total Sales by Segment')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.write.mode('overwrite').parquet(\"../../../data/curated/removed_outliers.parquet\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
