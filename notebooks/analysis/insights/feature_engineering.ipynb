{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, functions as f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "23/09/25 17:07:05 WARN Utils: Your hostname, DulanComputer resolves to a loopback address: 127.0.1.1; using 172.30.15.25 instead (on interface eth0)\n",
      "23/09/25 17:07:05 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/09/25 17:07:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/09/25 17:07:10 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/09/25 17:07:10 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    }
   ],
   "source": [
    "spark = (\n",
    "    SparkSession.builder.appName(\"feature_engineering\")\n",
    "    .config(\"spark.sql.repl.eagerEval.enabled\", True) \n",
    "    .config(\"spark.sql.parquet.cacheMetadata\", \"true\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config(\"spark.sql.session.timeZone\", \"Etc/UTC\")\n",
    "    .config('spark.driver.memory', '3g')   \n",
    "    .config('spark.executor.memory', '4g')  \n",
    "    .config('spark.executor.instances', '2')  \n",
    "    .config('spark.executor.cores', '2')\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "merchant_agg = spark.read.parquet(\"../../../data/insights/agg_insight_data/merchant_agg.parquet/\")\n",
    "consumers_agg = spark.read.parquet(\"../../../data/insights/agg_insight_data/consumers_agg.parquet/\")\n",
    "orders_agg = spark.read.parquet(\"../../../data/insights/agg_insight_data/orders_agg.parquet/\")\n",
    "postcode_agg = spark.read.parquet(\"../../../data/insights/agg_insight_data/postcode_agg.parquet/\")\n",
    "descriptions_agg = spark.read.parquet(\"../../../data/insights/agg_insight_data/descriptions_agg.parquet/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "consumers = spark.read.parquet(\"../../../data/insights/pre_insights/consumers.parquet/\")\n",
    "orders = spark.read.parquet(\"../../../data/insights/pre_insights/orders.parquet/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orders.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "merchant_consumer_average = orders.groupBy(\"merchant_abn\",\"consumer_id\").agg(f.sum(\"dollar_value\").alias(\"total_spend_per_consumer\"))\n",
    "merchant_consumer_average = merchant_consumer_average.groupBy(\"merchant_abn\").agg(f.avg(\"total_spend_per_consumer\").alias(\"average_spend_per_consumer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 9:====================================================>      (8 + 1) / 9]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------------------+\n",
      "|merchant_abn|average_spend_per_consumer|\n",
      "+------------+--------------------------+\n",
      "| 19839532017|        159.86401326699834|\n",
      "| 83412691377|          46.4000846912309|\n",
      "| 15613631617|          315.700802676049|\n",
      "| 38700038932|        1550.4022078249302|\n",
      "| 73256306726|        317.58976340347914|\n",
      "| 35344855546|         91.78943593346469|\n",
      "| 73841664453|         87.59171223895788|\n",
      "| 48214071373|         306.0637205405626|\n",
      "| 12516851436|        155.86384791171375|\n",
      "| 38986645707|        1031.5731096909874|\n",
      "| 96946925998|        1004.9578845656821|\n",
      "| 41956465747|        226.81527845616137|\n",
      "| 52763133264|        116.72171057856686|\n",
      "| 92202115241|        330.38147284030697|\n",
      "| 57798993346|         968.0714002697254|\n",
      "| 34440496342|         89.50534437869504|\n",
      "| 60654402457|         85.82341862233385|\n",
      "| 78916025936|        339.50799089182885|\n",
      "| 37935728745|        10533.823996552705|\n",
      "| 29216160692|        118.16188003728709|\n",
      "+------------+--------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "merchant_consumer_average.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
